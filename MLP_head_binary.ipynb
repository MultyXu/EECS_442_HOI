{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15770,"status":"ok","timestamp":1700237308647,"user":{"displayName":"Ruihan Xu (Multy)","userId":"12479151467308550886"},"user_tz":300},"id":"92AvwbQrAmEo","outputId":"24716b76-5935-422f-acf7-0179e0d6f473"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","Looks that a private key is already created. If you have already push it to github, no action required.\n"," Otherwise, Please go to https://github.com/settings/ssh/new to upload the following key: \n","ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICeyklL46g42c+kOiDGQYpBIkUVa8Oott1qwDIqq8fti root@8ae8a1039f30\n","\n","Please use SSH method to clone repo.\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","!wget -q https://raw.githubusercontent.com/tsunrise/colab-github/main/colab_github.py\n","import colab_github\n","colab_github.github_auth(persistent_key=True)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12110,"status":"ok","timestamp":1700261058742,"user":{"displayName":"Ruihan Xu (Multy)","userId":"12479151467308550886"},"user_tz":300},"id":"vK3HzGDCCY5d","outputId":"211c67fd-4896-4f25-c737-ec23cc4c12ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch Version:  2.1.0+cu118\n","Torchvision Version:  0.16.0+cu118\n","WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\n"]}],"source":["import pickle\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import copy\n","from tqdm import tqdm\n","\n","import torch\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","if torch.cuda.is_available():\n","    print(\"Using the GPU!\")\n","else:\n","    print(\"WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cWttABtwCh1m"},"outputs":[],"source":["input_size = 4096 #depends on the feature it will be fed into\n","layers = [2048, 512, 128] # define number of layer and layer size, need to experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qHuuql-cDDnP"},"outputs":[],"source":["class MLP(nn.Module):\n","\n","    def __init__(self, input_size, layers, drop_out_rate=0.3, num_classes=2, init_weights=True):\n","        super(MLP, self).__init__()\n","\n","        # construct a simple MLP that do binary classification on interactiveness\n","        self.input_size = input_size\n","        self.layers = layers\n","        # self.avgpool = nn.AdaptiveAvgPool2d((5, 5))\n","\n","        layer_dic = []\n","        last_layer = input_size\n","        for layer in layers:\n","          layer_dic.append(nn.Linear(last_layer, layer, True, device=device))\n","          layer_dic.append(nn.ReLU(True))\n","          layer_dic.append(nn.Dropout(0.3))\n","          last_layer = layer\n","\n","        layer_dic.append(nn.Linear(last_layer, 2, True))\n","\n","        self.classifier = nn.Sequential(*layer_dic)\n","\n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.classifier(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCle5cM_HV46"},"outputs":[],"source":["# define constant for hyperparameters\n","LR = 1e-2 # learning rate\n","DECAY = 1e-2 # decay rate\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_V5ZBkVH4nY"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, save_dir = None, num_epochs=25, model_name='MiniVGG'):\n","    \"\"\"\n","    Args:\n","        model: The NN to train\n","        dataloaders: A dictionary containing at least the keys\n","                    'train','val' that maps to Pytorch data loaders for the dataset\n","        criterion: The Loss function\n","        optimizer: Pytroch optimizer. The algorithm to update weights\n","        num_epochs: How many epochs to train for\n","        save_dir: Where to save the best model weights that are found. Using None will not write anything to disk.\n","\n","    Returns:\n","        model: The trained NN\n","        tr_acc_history: list, training accuracy history. Recording freq: one epoch.\n","        val_acc_history: list, validation accuracy history. Recording freq: one epoch.\n","    \"\"\"\n","\n","    val_acc_history = []\n","    tr_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            # loss and number of correct prediction for the current batch\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            # TQDM has nice progress bars\n","            for inputs, labels in tqdm(dataloaders[phase]):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                ###############################################################\n","                # TODO:                                                       #\n","                # Please read all the inputs carefully!                       #\n","                # For \"train\" phase:                                          #\n","                # (i)   Compute the outputs using the model                   #\n","                #       Also, use the  outputs to calculate the class         #\n","                #       predicted by the model,                               #\n","                #       Store the predicted class in 'preds'                  #\n","                #       (Think: argmax of outputs across a dimension)         #\n","                #       torch.max() might help!                               #\n","                # (ii)  Use criterion to store the loss in 'loss'             #\n","                # (iii) Update the model parameters                           #\n","                # Notes:                                                      #\n","                # - Don't forget to zero the gradients before beginning the   #\n","                # loop!                                                       #\n","                # - \"val\" phase is the same as train, but without backprop    #\n","                # - Compute the outputs (Same as \"train\", calculate 'preds'   #\n","                # too),                                                       #\n","                # - Calculate the loss and store it in 'loss'                 #\n","                ###############################################################\n","\n","                optimizer.zero_grad() # zero the grad\n","                outputs = model.forward(inputs)\n","                preds = torch.argmax(outputs, dim=1)\n","                loss = criterion(outputs, labels.data)\n","                if phase == 'train':\n","                  loss.backward()\n","                  optimizer.step()\n","\n","\n","                ###############################################################\n","                #                         END OF YOUR CODE                    #\n","                ###############################################################\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","                # save the best model weights\n","                # =========================================================== #\n","                # IMPORTANT:\n","                # Losing your connection to colab will lead to loss of trained\n","                # weights.\n","                # You should download the trained weights to your local machine.\n","                # Later, you can load these weights directly without needing to\n","                # train the neural networks again.\n","                # =========================================================== #\n","                if save_dir:\n","                    torch.save(best_model_wts, os.path.join(save_dir, model_name + '.pth'))\n","\n","            # record the train/val accuracies\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","            else:\n","                tr_acc_history.append(epoch_acc)\n","\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    return model, tr_acc_history, val_acc_history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aqUqALbKIA7h"},"outputs":[],"source":["# set up the model\n","interactive_net = MLP(input_size, layers)\n","\n","optimizer = optim.Adam(interactive_net.parameters, lr=LR, weight_decay=DECAY)\n","loos = nn.CrossEntropyLoss()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNP02UYFziJSpp/E0j+pvTw","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
